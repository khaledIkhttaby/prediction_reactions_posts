{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(probability=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from services_featuers.get_featuers_posts import get_featuers_for_post ,get_vector_category_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../data/Data_cleaning_with_content.csv\")\n",
    "reactions=['love','wow','angry','sad','care']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "contents=data['contentclean'].values\n",
    "love=data['love'].values\n",
    "wow=data['wow'].values\n",
    "sad=data['sigh'].values\n",
    "angry=data['grrr'].values\n",
    "care=data['care'].values\n",
    "category=data['category'].values\n",
    "sum_reaction=data['sumreactions'].values\n",
    "love=love/sum_reaction\n",
    "wow=wow/sum_reaction\n",
    "angry=angry/sum_reaction\n",
    "sad=sad/sum_reaction\n",
    "care=care/sum_reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions=np.array([love]).reshape(-1,1)\n",
    "Emotions=np.insert(Emotions,1,wow,axis=1)\n",
    "Emotions=np.insert(Emotions,2,angry,axis=1)\n",
    "Emotions=np.insert(Emotions,3,sad,axis=1)\n",
    "Emotions=np.insert(Emotions,4,care,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000127759665E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000127759665E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000127779819D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000127779819D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000012775966318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000012775966318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000127769F33A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000127769F33A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "536.0777430534363\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s=time.time()\n",
    "X_train=get_featuers_for_post(contents) \n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20443, 36)\n",
      "(20443, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               4736      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 21,893\n",
      "Trainable params: 21,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000127727234C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000127727234C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "510/512 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.7569WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012760EF5EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012760EF5EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "512/512 [==============================] - 5s 8ms/step - loss: 0.0451 - accuracy: 0.7572 - val_loss: 0.0217 - val_accuracy: 0.8606\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.8490 - val_loss: 0.0203 - val_accuracy: 0.8540\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.8504 - val_loss: 0.0199 - val_accuracy: 0.8547\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.8552 - val_loss: 0.0202 - val_accuracy: 0.8557\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.8607 - val_loss: 0.0192 - val_accuracy: 0.8564\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.8523 - val_loss: 0.0192 - val_accuracy: 0.8621\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.8626 - val_loss: 0.0196 - val_accuracy: 0.8545\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.8571 - val_loss: 0.0193 - val_accuracy: 0.8618\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.8575 - val_loss: 0.0189 - val_accuracy: 0.8601\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.8531 - val_loss: 0.0195 - val_accuracy: 0.8489\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.8592 - val_loss: 0.0190 - val_accuracy: 0.8640\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.8671 - val_loss: 0.0190 - val_accuracy: 0.8689\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.8669 - val_loss: 0.0194 - val_accuracy: 0.8692\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.8676 - val_loss: 0.0193 - val_accuracy: 0.8435\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.8625 - val_loss: 0.0193 - val_accuracy: 0.8557\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.8638 - val_loss: 0.0190 - val_accuracy: 0.8714\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.8627 - val_loss: 0.0189 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.8661 - val_loss: 0.0190 - val_accuracy: 0.8684\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.8613 - val_loss: 0.0192 - val_accuracy: 0.8694\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.8631 - val_loss: 0.0190 - val_accuracy: 0.8582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12760fab408>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "DROPOUT=0.3\n",
    "model.add(Dense(units=128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "                loss='mse',\n",
    "                 metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../Final_models_svm/model_nn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_love = LinearRegression().fit(X_train,love)\n",
    "reg_wow = LinearRegression().fit(X_train,wow)\n",
    "reg_angry = LinearRegression().fit(X_train,angry)\n",
    "reg_sad = LinearRegression().fit(X_train,sad)\n",
    "reg_care = LinearRegression().fit(X_train,care)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_models={\"love\":reg_love,\"wow\":reg_wow,\"angry\":reg_angry,\"sad\":reg_sad,\"care\":reg_care}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for k,v in svm_models.items():\n",
    "    \n",
    "    with open(\"../Final_models_svm/reg_\"+k+\".pickle\",\"wb\") as file:\n",
    "        pickle.dump(v,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
