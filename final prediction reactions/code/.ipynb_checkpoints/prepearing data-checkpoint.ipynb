{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepearing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>love</th>\n",
       "      <th>base_name</th>\n",
       "      <th>sigh</th>\n",
       "      <th>grrr</th>\n",
       "      <th>category</th>\n",
       "      <th>wow</th>\n",
       "      <th>care</th>\n",
       "      <th>content</th>\n",
       "      <th>sumreactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>سوريا اليوم</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Social</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>جديد قضية ابن بايدن.. الأف بي آي حقق مع شريكه ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>قناة العربية  Al Arabiya</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Social</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#هاااام :  بمتابعة واشراف من عمر حورية أمين ال...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>شام تايمز shamtimes.net</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Military</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>وَلَا تَحْسَبَنَّ اللَّهَ غَافِلًا عَمَّا يَعْ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>شبكة أخبار اللاذقية L.N.N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Religion</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>مسافرة أسترالية للعربية: تم اقتياد النساء والأ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>الياطر نيوز Alyater News</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Trump in 2016: “#Assad is killing #ISIS. #Russ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29942</th>\n",
       "      <td>0</td>\n",
       "      <td>المركز الاذاعي والتلفزيوني في السويداء</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#بث #مباشر - #برنامج #حق_المواطن_في_الإعلام  ض...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29943</th>\n",
       "      <td>48</td>\n",
       "      <td>تلفزيون اللاذقية _ Lattakia TV</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>Military</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>وتمضي الأيام والباسل في الذاكرة والوجدان ❤ فار...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29944</th>\n",
       "      <td>2</td>\n",
       "      <td>وزارة الاتصالات والتقانة - سورية</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>رئاسة مجلس الوزراء في سورية  وزارة الاتصالات و...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29945</th>\n",
       "      <td>1</td>\n",
       "      <td>الحرس الجمهوري السوري الالكتروني اللواء   105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Military</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>نائب رئيس المركز الروسي للمصالحة في سوريا: ناق...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29946</th>\n",
       "      <td>0</td>\n",
       "      <td>اللاذقية A.A.T شبكة ترفيه ومنوعات</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>لماذا العريس السوري في ليلة زفافه يسلم مفتاح س...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29947 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       love                                      base_name  sigh  grrr  \\\n",
       "0         5                                    سوريا اليوم     2     1   \n",
       "1         0                       قناة العربية  Al Arabiya     0     0   \n",
       "2         1                        شام تايمز shamtimes.net     0     0   \n",
       "3        27                      شبكة أخبار اللاذقية L.N.N     0     0   \n",
       "4         0                       الياطر نيوز Alyater News     0     0   \n",
       "...     ...                                            ...   ...   ...   \n",
       "29942     0         المركز الاذاعي والتلفزيوني في السويداء     0     0   \n",
       "29943    48                 تلفزيون اللاذقية _ Lattakia TV    72     0   \n",
       "29944     2               وزارة الاتصالات والتقانة - سورية     0     0   \n",
       "29945     1  الحرس الجمهوري السوري الالكتروني اللواء   105     0     0   \n",
       "29946     0              اللاذقية A.A.T شبكة ترفيه ومنوعات     0     0   \n",
       "\n",
       "        category  wow  care  \\\n",
       "0         Social    0     0   \n",
       "1         Social    0     0   \n",
       "2       Military    0     0   \n",
       "3       Religion    0     3   \n",
       "4       Politics    1     0   \n",
       "...          ...  ...   ...   \n",
       "29942  Education    0     0   \n",
       "29943   Military    1     5   \n",
       "29944   Politics    0     0   \n",
       "29945   Military    0     0   \n",
       "29946   Politics    0     0   \n",
       "\n",
       "                                                 content  sumreactions  \n",
       "0      جديد قضية ابن بايدن.. الأف بي آي حقق مع شريكه ...             8  \n",
       "1      #هاااام :  بمتابعة واشراف من عمر حورية أمين ال...             0  \n",
       "2      وَلَا تَحْسَبَنَّ اللَّهَ غَافِلًا عَمَّا يَعْ...             1  \n",
       "3      مسافرة أسترالية للعربية: تم اقتياد النساء والأ...            30  \n",
       "4      Trump in 2016: “#Assad is killing #ISIS. #Russ...             1  \n",
       "...                                                  ...           ...  \n",
       "29942  #بث #مباشر - #برنامج #حق_المواطن_في_الإعلام  ض...             0  \n",
       "29943  وتمضي الأيام والباسل في الذاكرة والوجدان ❤ فار...           126  \n",
       "29944  رئاسة مجلس الوزراء في سورية  وزارة الاتصالات و...             2  \n",
       "29945  نائب رئيس المركز الروسي للمصالحة في سوريا: ناق...             1  \n",
       "29946  لماذا العريس السوري في ليلة زفافه يسلم مفتاح س...             0  \n",
       "\n",
       "[29947 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=pd.read_csv(\"../data/Data.csv\")\n",
    "all_data=all_data.drop(columns=['base_url','likes'])\n",
    "all_data['sumreactions']=all_data['love']+all_data['sigh']+all_data['wow']+all_data['care']+all_data['grrr']\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_negative = all_data[ all_data['sumreactions'] < 1 ] # Step 1\n",
    "all_data = all_data.drop(df_age_negative.index, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"Data_cleaning_with_thresh_1.csv\",index=False)\n",
    "\n",
    "# x.to_csv(\"Data_cleaning_with_thresh_5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def split_emoji(txt):\n",
    "    x=' '.join(c for c in txt.split() if c not in emoji.UNICODE_EMOJI)\n",
    "    return x\n",
    "#     em = txt\n",
    "#     em_split_emoji = emoji.get_emoji_regexp().split(em)\n",
    "#     em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "#     em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "#     res = ''\n",
    "\n",
    "#     for i in range(len(em_split)):\n",
    "#         if em_split[i] not in emoji.UNICODE_EMOJI:\n",
    "#             if i != len(em_split) - 1:\n",
    "#                 res += em_split[i] + ' '\n",
    "#             else:\n",
    "#                 res += em_split[i]\n",
    "#         else:\n",
    "#             continue\n",
    "#     return res\n",
    "\n",
    "stop_word=pd.read_csv(\"../data/stopwords.csv\",names=['data'])['data'].values\n",
    "i=0\n",
    "def len_sent(text):\n",
    "    return len(text.split())\n",
    "def preprocessing(data ):\n",
    "    data=str(data)\n",
    "    data = split_emoji(data)\n",
    "    data = str(' '.join(re.sub(\"([٠١٢٣٤٥٦٧٨٩]+)|([0-9]+)|([A-Za-z]+)|\\_+|(\\#)+|(\\/)+|(\\:)+\", \" \", data).split()))\n",
    "    data = re.sub(\"[إأٱآا]\", \"ا\", data)\n",
    "    data = re.sub(\"ة\", \"ه\", data)\n",
    "    # remove duplicate\n",
    "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                            َ    | # Fatha\n",
    "                            ً    | # Tanwin Fath\n",
    "                            ُ    | # Damma\n",
    "                            ٌ    | # Tanwin Damm\n",
    "                            ِ    | # Kasra\n",
    "                            ٍ    | # Tanwin Kasr\n",
    "                            ْ    | # Sukun\n",
    "                            ـ   |  # Tatwil/Kashida\n",
    "                            ،   |\n",
    "                        \"\"\", re.VERBOSE)\n",
    "    flagsUs = re.compile(\"[\"\n",
    "                         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                         \"]+\", flags=re.UNICODE)\n",
    "    dirtyChars = re.compile(\"[\"\n",
    "                            \"\\u0600-\\u0620\"\n",
    "                            \"\\u063B-\\u0640\"\n",
    "                            \"\\u064B-\\u065F\"\n",
    "                            \"\\u066A-\\u06FF\"\n",
    "                            \"\\u0750-\\u077F\"\n",
    "                            \"\\u08A0-\\u08FF\"\n",
    "                            \"\\uFB50-\\uFBE9\"\n",
    "                            \"\\uFBF0-\\uFBFB\"\n",
    "                            \"\\uFC5B-\\uFC63\"\n",
    "                            \"\\uFCF2-\\uFCF4\"\n",
    "                            \"\\uFD3C-\\uFD4F\"\n",
    "                            \"\\uFD90-\\uFD91\"\n",
    "                            \"\\uFDC8-\\uFDFF\"\n",
    "                            \"\\uFE70-\\uFE7F\"\n",
    "                            \"\\uFEFD-\\uFEFF\"\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "    data = str(re.sub(flagsUs, '', data))\n",
    "    data = str(re.sub(dirtyChars, '', data))\n",
    "    data = str(re.sub(noise, '', data))\n",
    "#     data = str(''.join(c for c in data if c not in punctuation))\n",
    "    data = re.sub(\n",
    "        '\\/+|\\●+|\\◽+|\\٪+|\\▪+|\\»+|\\«+|\\_+|\\ʚïɞ+|\\▐+|\\►+|\\\"+|\\*+|\\▁+|\\》+|\\《+|\\[+|\\Ещё+|\\]+|\\|+|\\;+|\\'+|\\<+|\\>+|\\\\+|\\`+|\\{+|\\}+|\\~+|\\\"+|\\-+|\\:+|\\@+|\\#+|\\$+|\\ﷺ+|\\%+|\\^+|\\&+|\\(+|\\)+|\\.+|\\,+|\\?+|\\=+|\\++|\\؛+\\“+|\\”+',\n",
    "        ' ', data)\n",
    "    data = re.sub('\\!', '  ', data)\n",
    "    data = re.sub('\\⚘', '  ', data)\n",
    "    data = re.sub('\\��', '  ', data)\n",
    "    data = re.sub('\\؟ ', ' ', data)\n",
    "    data = re.sub('\\.', ' ', data)\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "    data = re.sub('\\\\\\+', ' ', data)\n",
    "    data = re.sub('\\\"+',' ',data)\n",
    "    data = re.sub(' ا ', ' ', data)\n",
    "    data = re.sub(' ب ', ' ', data)\n",
    "    data = re.sub(' ت ', ' ', data)\n",
    "    data = re.sub(' ث ', ' ', data)\n",
    "    data = re.sub(' ج ', ' ', data)\n",
    "    data = re.sub(' ح ', ' ', data)\n",
    "    data = re.sub(' خ ', ' ', data)\n",
    "    data = re.sub(' د ', ' ', data)\n",
    "    data = re.sub(' ذ ', ' ', data)\n",
    "    data = re.sub(' ر ', ' ', data)\n",
    "    data = re.sub(' ز ', ' ', data)\n",
    "    data = re.sub(' س ', ' ', data)\n",
    "    data = re.sub(' ش ', ' ', data)\n",
    "    data = re.sub(' ص ', ' ', data)\n",
    "    data = re.sub(' ض ', ' ', data)\n",
    "    data = re.sub(' ط ', ' ', data)\n",
    "    data = re.sub(' ظ ', ' ', data)\n",
    "    data = re.sub(' ع ', ' ', data)\n",
    "    data = re.sub(' غ ', ' ', data)\n",
    "    data = re.sub(' ف ', ' ', data)\n",
    "    data = re.sub(' ق ', ' ', data)\n",
    "    data = re.sub(' ك ', ' ', data)\n",
    "    data = re.sub(' ل ', ' ', data)\n",
    "    data = re.sub(' م ', ' ', data)\n",
    "    data = re.sub(' ن ', ' ', data)\n",
    "    data = re.sub(' ه ', ' ', data)\n",
    "    data = re.sub(' و ', ' ', data)\n",
    "    data = re.sub(' ي ', ' ', data)\n",
    "    data = re.sub(' ئ ', ' ', data)\n",
    "    data = re.sub(' ؤ ', ' ', data)\n",
    "    data = re.sub(' ء ', ' ', data)\n",
    "    data = re.sub('\\_+', ' ', data)\n",
    "    data = re.sub('\\…+', ' ', data)\n",
    "    data = re.sub('\\“|\\”', '', data)\n",
    "    data = re.sub(r'([\\u0600-\\u06FF])\\1{3,}', r'\\1\\1\\1', data)\n",
    "    data = re.sub(r'[\\u2066]', ' ', data)\n",
    "    data = re.sub(r'[\\u2069]', ' ', data)\n",
    "    data = re.sub(r'[\\uFE0F]', ' ', data)\n",
    "    data = re.sub(r'[\\u25a0]', ' ', data)\n",
    "    data = re.sub(r'[\\u2022]', ' ', data)\n",
    "    data = re.sub(r'[\\u2592]', ' ', data)\n",
    "    data = re.sub('[\\u1ea0]|[\\u1ea1]|[\\u1e97]|[\\u1ea1]|[\\u02bf]|[\\u1e97]|[\\u1ea1]|[\\u1e97]|[\\u1ea1]|[\\u1ea1]|[\\u02be]|[\\u1ea1]|[\\u1ea1]',' ',data)\n",
    "    data = ' '.join([word for word in data.split() if word not in stop_word])\n",
    "    data = \" \".join(data.split())\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['contentclean']=all_data['content'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataprepeard\\\\Data_cleaning_with_content.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-978ae1aafd9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataprepeard\\\\Data_cleaning_with_content.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             )\n\u001b[0;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataprepeard\\\\Data_cleaning_with_content.csv'"
     ]
    }
   ],
   "source": [
    "all_data.to_csv(\"../data/Data_cleaning_with_content.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
