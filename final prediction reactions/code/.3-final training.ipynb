{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(probability=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "get_ipython().run_line_magic('config', 'Completer.use_jedi = False')\n",
    "from services_featuers.get_category_vector_svm__ import get_category_vector\n",
    "from services_featuers.get_category_vector_nn import get_category_vector_nn\n",
    "from services_featuers.get_emotion_vector import get_emotion_vector_svm\n",
    "from services_featuers.get_emotion_vector_NN import get_emotion_vecor_nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "def concatentate_tow_numpyarray(a,b):\n",
    "    k=list()\n",
    "    for i in range(len(b)):\n",
    "        k.append(a[i].tolist()+b[i].tolist())\n",
    "    return np.array(k)\n",
    "def get_vector_category_full(post):\n",
    "    return concatentate_tow_numpyarray(get_category_vector(post),get_category_vector_nn(post))\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "def get_vector_emotion_full(post):\n",
    "    return concatentate_tow_numpyarray(get_emotion_vector_svm(post),get_emotion_vecor_nn(post))\n",
    "\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "def convert_to_one_vector(nparray):\n",
    "    l=list()\n",
    "    for s in nparray:\n",
    "        l=l+s.tolist()\n",
    "    return np.array(l)\n",
    "def get_featuers_for_post(post):\n",
    "    return concatentate_tow_numpyarray(get_vector_category_full(post),get_vector_emotion_full(post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../data/Data_cleaning_with_content.csv\")\n",
    "reactions=['love','wow','angry','sad','care']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "contents=data['contentclean'].values\n",
    "love=data['love'].values\n",
    "wow=data['wow'].values\n",
    "sad=data['sigh'].values\n",
    "angry=data['grrr'].values\n",
    "care=data['care'].values\n",
    "category=data['category'].values\n",
    "sum_reaction=data['sumreactions'].values\n",
    "love=love/sum_reaction\n",
    "wow=wow/sum_reaction\n",
    "angry=angry/sum_reaction\n",
    "sad=sad/sum_reaction\n",
    "care=care/sum_reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions=np.array([love]).reshape(-1,1)\n",
    "Emotions=np.insert(Emotions,1,wow,axis=1)\n",
    "Emotions=np.insert(Emotions,2,angry,axis=1)\n",
    "Emotions=np.insert(Emotions,3,sad,axis=1)\n",
    "Emotions=np.insert(Emotions,4,care,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-329242025600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_featuers_for_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-8fe7a80e822a>\u001b[0m in \u001b[0;36mget_featuers_for_post\u001b[1;34m(post)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_featuers_for_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatentate_tow_numpyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_vector_category_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mget_vector_emotion_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-8fe7a80e822a>\u001b[0m in \u001b[0;36mget_vector_category_full\u001b[1;34m(post)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vector_category_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatentate_tow_numpyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_category_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mget_category_vector_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\final prediction reactions\\code\\services_featuers\\get_category_vector_svm__.py\u001b[0m in \u001b[0;36mget_category_vector\u001b[1;34m(post)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_category_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredict_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC_category\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTF_Vecorize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mget_category_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"جديد قضيه ابن بايدن الاف بي حقق شريكه ساعات \"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\final prediction reactions\\code\\services_featuers\\get_category_vector_svm__.py\u001b[0m in \u001b[0;36mpredict_svm\u001b[1;34m(clf, post, tfidf)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mpost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    665\u001b[0m         pred_proba = (self._sparse_predict_proba\n\u001b[0;32m    666\u001b[0m                       if self._sparse else self._dense_predict_proba)\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_sparse_predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             self._probA, self._probB)\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_coef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "s=time.time()\n",
    "X_train=get_featuers_for_post(contents) \n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               4736      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 21,893\n",
      "Trainable params: 21,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000127727234C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000127727234C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "510/512 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.7569WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012760EF5EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012760EF5EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "512/512 [==============================] - 5s 8ms/step - loss: 0.0451 - accuracy: 0.7572 - val_loss: 0.0217 - val_accuracy: 0.8606\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.8490 - val_loss: 0.0203 - val_accuracy: 0.8540\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.8504 - val_loss: 0.0199 - val_accuracy: 0.8547\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.8552 - val_loss: 0.0202 - val_accuracy: 0.8557\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.8607 - val_loss: 0.0192 - val_accuracy: 0.8564\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.8523 - val_loss: 0.0192 - val_accuracy: 0.8621\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.8626 - val_loss: 0.0196 - val_accuracy: 0.8545\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.8571 - val_loss: 0.0193 - val_accuracy: 0.8618\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.8575 - val_loss: 0.0189 - val_accuracy: 0.8601\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.8531 - val_loss: 0.0195 - val_accuracy: 0.8489\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.8592 - val_loss: 0.0190 - val_accuracy: 0.8640\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.8671 - val_loss: 0.0190 - val_accuracy: 0.8689\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.8669 - val_loss: 0.0194 - val_accuracy: 0.8692\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.8676 - val_loss: 0.0193 - val_accuracy: 0.8435\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.8625 - val_loss: 0.0193 - val_accuracy: 0.8557\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.8638 - val_loss: 0.0190 - val_accuracy: 0.8714\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.8627 - val_loss: 0.0189 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.8661 - val_loss: 0.0190 - val_accuracy: 0.8684\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.8613 - val_loss: 0.0192 - val_accuracy: 0.8694\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.8631 - val_loss: 0.0190 - val_accuracy: 0.8582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12760fab408>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "DROPOUT=0.3\n",
    "model.add(Dense(units=128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "                loss='mse',\n",
    "                 metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../Final_models_svm/model_nn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_love = LinearRegression().fit(X_train,love)\n",
    "reg_wow = LinearRegression().fit(X_train,wow)\n",
    "reg_angry = LinearRegression().fit(X_train,angry)\n",
    "reg_sad = LinearRegression().fit(X_train,sad)\n",
    "reg_care = LinearRegression().fit(X_train,care)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_models={\"love\":reg_love,\"wow\":reg_wow,\"angry\":reg_angry,\"sad\":reg_sad,\"care\":reg_care}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for k,v in svm_models.items():\n",
    "    \n",
    "    with open(\"../Final_models_svm/reg_\"+k+\".pickle\",\"wb\") as file:\n",
    "        pickle.dump(v,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
